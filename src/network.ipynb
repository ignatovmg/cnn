{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release.  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 750 Ti (CNMeM is disabled, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import lasagne\n",
    "import lasagne.layers.dnn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = np.random.randn(300, 3, 20, 20, 20).astype(np.float32)\n",
    "target = ((np.random.randn(300)+1)/2).astype(np.int32)                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  0,  1,  0,  0,  0,  0,  1,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,  0,\n",
       "        0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  2,  0,  0,\n",
       "        0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  1,  0,  0,  1,  0,  0,  0,  0,  1,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  1,  0,  0,  0,  0,  0,\n",
       "        0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,\n",
       "        0,  1,  0,  1,  0,  0,  0,  0,  1,  1,  0,  0,  0,  0,  0,  1,  0,\n",
       "        1,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  1,  0,  1,  1,\n",
       "        1,  0,  1,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,\n",
       "        0,  0,  0,  1,  0,  0,  0,  0,  1,  0,  0], dtype=int32)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtensor5 = T.TensorType('float32', (False,)*5)\n",
    "input_var = dtensor5('input')\n",
    "target_var = T.ivector('target')\n",
    "\n",
    "network = lasagne.layers.InputLayer((300, 3, 20, 20, 20), input_var=input_var)\n",
    "network = lasagne.layers.dnn.Conv3DDNNLayer(lasagne.layers.DropoutLayer(network, 0.5), \n",
    "                                            num_filters=10, filter_size=(4,4,4))\n",
    "network = lasagne.layers.dnn.Conv3DDNNLayer(lasagne.layers.DropoutLayer(network, 0.5), \n",
    "                                            num_filters=10, filter_size=(4,4,4))\n",
    "network = lasagne.layers.DenseLayer(network, num_units=30, nonlinearity=lasagne.nonlinearities.softmax)\n",
    "network = lasagne.layers.DenseLayer(network, num_units=2, nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n",
    "prediction = lasagne.layers.get_output(network)\n",
    "loss = lasagne.objectives.categorical_crossentropy(prediction, target_var).mean()\n",
    "\n",
    "params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "updates = lasagne.updates.nesterov_momentum(loss, params, learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "train_fn = theano.function([input_var, target_var], loss, updates=updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.3995228707790375, dtype=float32)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fn(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_fn = theano.function([input_var], prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543444],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543444],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543444],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456539,  0.15543461],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543444],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.1554345 ],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543444],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543444],\n",
       "       [ 0.84456551,  0.15543444],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543444],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543444],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.1554345 ],\n",
       "       [ 0.84456551,  0.1554345 ],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543444],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543453],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.1554345 ],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543444],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543444],\n",
       "       [ 0.84456551,  0.15543444],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543449],\n",
       "       [ 0.84456551,  0.15543446],\n",
       "       [ 0.84456551,  0.15543446]], dtype=float32)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fn(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.randn(1, 1, 20, 20, 20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax.0\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(1.0), array(-1.0)]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = T.dscalar('a')\n",
    "b = T.dscalar('b')\n",
    "z = a ** a - b ** b\n",
    "fun = theano.function([a, b], T.grad(z, [a, b]))\n",
    "fun(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   2.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
       "       [   0.,    2.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
       "       [   0.,    0.,    4.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
       "       [   0.,    0.,    0.,    6.,    0.,    0.,    0.,    0.,    0.],\n",
       "       [   0.,    0.,    0.,    0.,   12.,    0.,    0.,    0.,    0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,   90.,    0.,    0.,    0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,   16.,    0.,    0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,   12.,    0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,  134.]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = T.dvector('v')\n",
    "z = v ** 2\n",
    "w, updates = theano.scan(lambda i: T.grad(z[i], v), sequences=T.arange(v.shape[0]))\n",
    "fun = theano.function([v], w)\n",
    "fun([1, 1, 2,3, 6,45, 8,6,67])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
